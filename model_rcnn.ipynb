{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed1e14d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matvejzasadko/.pyenv/versions/3.8.13/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/matvejzasadko/.pyenv/versions/3.8.13/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.ops as ops \n",
    "from torchvision.ops import roi_pool\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8535a5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'filename': [],\n",
    "    'width': [],\n",
    "    'height': [],\n",
    "    'class': [],\n",
    "    'xmin': [],\n",
    "    'ymin': [],\n",
    "    'xmax': [],\n",
    "    'ymax': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2e10652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_image_dimensions(file_path):\n",
    "    if not os.path.isfile(file_path):\n",
    "        return None, None\n",
    "    with Image.open(file_path) as img:\n",
    "        width, height = img.size\n",
    "    return width, height\n",
    "\n",
    "def get_xml_image_dimensions(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    size = root.find('size')\n",
    "    if size is not None:\n",
    "        width = size.find('width').text\n",
    "        height = size.find('height').text\n",
    "        if width and height:\n",
    "            return int(width), int(height)\n",
    "    return 0, 0  \n",
    "\n",
    "\n",
    "def get_image_dimensions(xml_file, image_file_path):\n",
    "    width, height = get_xml_image_dimensions(xml_file)\n",
    "    \n",
    "    if width == 0 or height == 0:\n",
    "        width, height = get_file_image_dimensions(image_file_path)\n",
    "        \n",
    "    return width, height\n",
    "\n",
    "\n",
    "def parse_xml(xml_file, image_file_path):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    filename = root.find('filename').text\n",
    "    \n",
    "    width, height = get_image_dimensions(xml_file, image_file_path)\n",
    "\n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "        obj_class = obj.find('name').text\n",
    "        bbox = obj.find('bndbox')\n",
    "        xmin = int(bbox.find('xmin').text)\n",
    "        ymin = int(bbox.find('ymin').text)\n",
    "        xmax = int(bbox.find('xmax').text)\n",
    "        ymax = int(bbox.find('ymax').text)\n",
    "\n",
    "        data['filename'].append(filename)\n",
    "        data['width'].append(width)\n",
    "        data['height'].append(height)\n",
    "        data['class'].append(obj_class)\n",
    "        data['xmin'].append(xmin)\n",
    "        data['ymin'].append(ymin)\n",
    "        data['xmax'].append(xmax)\n",
    "        data['ymax'].append(ymax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acdeeb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FruitDataset(Dataset):\n",
    "    def __init__(self, data_dir, transforms=None, image_size=(256, 256)):\n",
    "        self.data_dir = data_dir\n",
    "        self.transforms = transforms\n",
    "        self.image_size = image_size \n",
    "        \n",
    "        self.images = [f for f in os.listdir(data_dir) if f.endswith('.jpg')]\n",
    "        \n",
    "        for image_file in self.images:\n",
    "            xml_file = image_file.replace('.jpg', '.xml')\n",
    "            xml_path = os.path.join(data_dir, xml_file)\n",
    "            image_path = os.path.join(data_dir, image_file)\n",
    "            if os.path.exists(xml_path):\n",
    "                parse_xml(xml_path, image_path)\n",
    "        \n",
    "        self.dataframe = pd.DataFrame(data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def class_to_label(self, class_name):\n",
    "        class_mapping = {'apple': 0, 'banana': 1, 'orange': 2}\n",
    "        return class_mapping.get(class_name, 0) \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.images[idx]\n",
    "        image_path = os.path.join(self.data_dir, image_name)\n",
    "\n",
    "    # Завантажуємо зображення\n",
    "        image = cv2.imread(image_path)\n",
    "    \n",
    "    # Перетворюємо в RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "    \n",
    "        image_data = self.dataframe[self.dataframe['filename'] == image_name]\n",
    "        for _, row in image_data.iterrows():\n",
    "            xmin = row['xmin']\n",
    "            ymin = row['ymin']\n",
    "            xmax = row['xmax']\n",
    "            ymax = row['ymax']\n",
    "            label = self.class_to_label(row['class'])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "            labels.append(label)\n",
    "    \n",
    "        orig_height, orig_width = image.shape[:2]\n",
    "    \n",
    "    # Приведення всіх зображень до одного розміру\n",
    "        image = cv2.resize(image, self.image_size)\n",
    "    \n",
    "    # Пропорційне масштабування bounding boxes\n",
    "        scale_x = self.image_size[0] / orig_width\n",
    "        scale_y = self.image_size[1] / orig_height\n",
    "        boxes = [[xmin * scale_x, ymin * scale_y, xmax * scale_x, ymax * scale_y] for xmin, ymin, xmax, ymax in boxes]\n",
    "    \n",
    "        boxes = [[xmin / self.image_size[0], ymin / self.image_size[1], xmax / self.image_size[0], ymax / self.image_size[1]] for xmin, ymin, xmax, ymax in boxes]\n",
    "\n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(image=image, bboxes=boxes, labels=labels)\n",
    "            image = transformed['image']\n",
    "            boxes = torch.as_tensor(transformed['bboxes'], dtype=torch.float32)\n",
    "\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "    \n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "    \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62420d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256]) tensor([[0.1370, 0.2783, 0.6315, 0.8035]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0000, 0.1158, 0.8675, 0.9570]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0227, 0.0014, 0.6516, 0.2972]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.1200, 0.1026, 0.8900, 0.8462]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.1092, 0.1378, 0.5130, 0.9212],\n",
      "        [0.4827, 0.0489, 0.8801, 0.7345]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0808, 0.0000, 0.9314, 1.0000]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0875, 0.0417, 0.3625, 0.3767],\n",
      "        [0.0437, 0.3617, 0.3162, 0.7550],\n",
      "        [0.2288, 0.2950, 0.4775, 0.6850],\n",
      "        [0.7563, 0.4967, 0.9837, 0.8550],\n",
      "        [0.6225, 0.6167, 0.8438, 0.9450],\n",
      "        [0.4162, 0.3983, 0.7175, 0.7717],\n",
      "        [0.2387, 0.5833, 0.4663, 0.9050],\n",
      "        [0.5537, 0.7083, 0.8188, 0.9967]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.6438, 0.4283, 0.9350, 0.8733],\n",
      "        [0.4238, 0.5750, 0.7225, 0.9483],\n",
      "        [0.0125, 0.3983, 0.2675, 0.7850],\n",
      "        [0.2412, 0.3183, 0.5288, 0.6767],\n",
      "        [0.5525, 0.2933, 0.7937, 0.5450],\n",
      "        [0.3762, 0.0367, 0.6662, 0.3600],\n",
      "        [0.6687, 0.0917, 0.8750, 0.3667]])\n",
      "torch.Size([3, 256, 256]) tensor([[0., 0., 1., 1.]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.3354, 0.2000, 0.7992, 0.6396]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.6484, 0.3545, 0.8625, 0.8127],\n",
      "        [0.6641, 0.1383, 0.8766, 0.5389],\n",
      "        [0.1344, 0.3401, 0.3406, 0.7579],\n",
      "        [0.0688, 0.1527, 0.3016, 0.5274],\n",
      "        [0.2844, 0.2161, 0.5078, 0.6311],\n",
      "        [0.3891, 0.3660, 0.6250, 0.7752],\n",
      "        [0.5172, 0.0922, 0.7250, 0.4553]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0807, 0.0821, 0.9206, 0.9190]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.4100, 0.1890, 0.9167, 0.9154]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0060, 0.0158, 1.0000, 0.9967]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0216, 0.5251, 0.3895, 0.9642],\n",
      "        [0.2535, 0.1495, 0.5815, 0.5567],\n",
      "        [0.4709, 0.2902, 0.8678, 0.7328],\n",
      "        [0.4241, 0.0094, 0.7456, 0.3765],\n",
      "        [0.1348, 0.0000, 0.4728, 0.3488]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.4300, 0.3620, 0.8120, 0.7400],\n",
      "        [0.6560, 0.3460, 0.9760, 0.7020]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.1757, 0.1920, 0.8431, 0.6920]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.2833, 0.2139, 0.8667, 0.8278]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.3931, 0.2109, 0.9515, 0.7851],\n",
      "        [0.0772, 0.1743, 0.5842, 0.6584]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256]) tensor([[0.1167, 0.3764, 0.4075, 0.8381],\n",
      "        [0.3242, 0.4228, 0.6817, 0.8632],\n",
      "        [0.5175, 0.3476, 0.8042, 0.7779],\n",
      "        [0.3042, 0.0765, 0.6708, 0.5257]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0240, 0.1080, 0.6840, 0.7720]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.2620, 0.2216, 0.7819, 0.7163]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.3841, 0.1253, 0.7331, 0.6071],\n",
      "        [0.1441, 0.2691, 0.4733, 0.7505],\n",
      "        [0.2077, 0.3587, 0.9765, 0.9639]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0833, 0.1400, 0.9167, 0.9900]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.2542, 0.2806, 0.6906, 0.8333],\n",
      "        [0.6917, 0.1778, 0.9573, 0.5125]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.1841, 0.0077, 1.0000, 1.0000]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.1654, 0.2305, 0.8808, 0.8475]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.1439, 0.1909, 0.9045, 0.8061]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0445, 0.0860, 0.9161, 1.0000]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0971, 0.3173, 0.8110, 0.9583],\n",
      "        [0.3272, 0.3655, 0.7860, 0.8553]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.1744, 0.1602, 0.4533, 0.6322],\n",
      "        [0.5063, 0.2069, 0.6959, 0.7214],\n",
      "        [0.5608, 0.1439, 0.8086, 0.5650],\n",
      "        [0.3557, 0.2236, 0.5438, 0.7396]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.4748, 0.4461, 0.8178, 0.8085],\n",
      "        [0.1865, 0.4369, 0.5484, 0.7599],\n",
      "        [0.2978, 0.2519, 0.6644, 0.5990]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.4866, 0.1982, 0.9626, 0.8939],\n",
      "        [0.1520, 0.1732, 0.4962, 0.6563],\n",
      "        [0.2827, 0.4739, 0.6569, 0.9573]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.3155, 0.0376, 1.0000, 0.7430],\n",
      "        [0.2428, 0.2185, 1.0000, 1.0000]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.1567, 0.1322, 0.9833, 1.0000]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256]) tensor([[0.1459, 0.0439, 0.6137, 0.6455],\n",
      "        [0.3771, 0.0852, 0.9082, 0.7686],\n",
      "        [0.0000, 0.2139, 0.8640, 1.0000]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.3040, 0.1097, 0.5176, 0.4501],\n",
      "        [0.5370, 0.1919, 0.7312, 0.5489],\n",
      "        [0.5070, 0.5134, 0.7493, 0.8748]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.4731, 0.3150, 0.9156, 0.9221],\n",
      "        [0.0705, 0.4095, 0.7230, 0.9517],\n",
      "        [0.0894, 0.2228, 0.7289, 0.6759]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.2165, 0.1702, 0.9529, 0.6170],\n",
      "        [0.0706, 0.2376, 0.5953, 1.0000],\n",
      "        [0.1788, 0.2695, 0.8659, 0.7979]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.4023, 0.1011, 0.7264, 0.8362]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0000, 0.1643, 1.0000, 1.0000]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.3169, 0.1390, 0.8575, 0.6669]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0080, 0.0740, 0.6800, 0.8000]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.1689, 0.1011, 0.8360, 0.9212],\n",
      "        [0.3617, 0.1165, 0.9677, 1.0000],\n",
      "        [0.0904, 0.0804, 0.7357, 0.7218]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0274, 0.2545, 0.4820, 0.8629],\n",
      "        [0.1570, 0.1419, 0.8432, 0.5604],\n",
      "        [0.2422, 0.3369, 0.8775, 0.8448]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.5109, 0.0488, 0.9025, 0.6109]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.1850, 0.6661, 0.3858, 0.9141],\n",
      "        [0.8295, 0.5663, 0.9703, 0.7532],\n",
      "        [0.7775, 0.4330, 0.9472, 0.6270],\n",
      "        [0.1858, 0.3822, 0.6115, 0.6508],\n",
      "        [0.2539, 0.4793, 0.6422, 0.7331],\n",
      "        [0.4609, 0.3704, 0.7369, 0.7322],\n",
      "        [0.5147, 0.4873, 0.7545, 0.8087],\n",
      "        [0.4545, 0.1992, 0.6466, 0.4558],\n",
      "        [0.6348, 0.2622, 0.8352, 0.5242]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0855, 0.0379, 0.5335, 0.6722],\n",
      "        [0.0853, 0.6248, 0.9764, 1.0000],\n",
      "        [0.5124, 0.0000, 0.9351, 0.6374]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0490, 0.1750, 0.4847, 0.9124],\n",
      "        [0.4858, 0.1033, 0.9934, 0.9909]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.1990, 0.3280, 0.8418, 0.8880]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0122, 0.3700, 0.8407, 1.0000]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.2896, 0.1253, 0.9035, 0.9896]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0473, 0.1156, 0.8504, 1.0000]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0803, 0.2033, 0.9021, 0.9760]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0534, 0.0806, 0.9377, 0.9403]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0202, 0.0403, 0.9514, 1.0000]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0383, 0.4350, 0.9820, 0.9831],\n",
      "        [0.2432, 0.2571, 0.9685, 0.6441],\n",
      "        [0.2568, 0.1017, 0.8761, 0.4831]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0518, 0.0503, 1.0000, 0.9746]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.1812, 0.3500, 0.8713, 0.8067]])\n",
      "torch.Size([3, 256, 256]) tensor([[0.0000, 0.5724, 0.8755, 0.9827]])\n"
     ]
    }
   ],
   "source": [
    "transform = A.Compose([\n",
    "    \n",
    "    # Дзеркально відображає зобреження, щоб в подальшому модель звикала до симетрії(обʼєкт може бути як ліворуч так і праворуч)\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    # Перевертає зображення щоб якщо обʼєкти були перевернутими, або нахиленимим, модель всеодно їх впізнавала\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    # Допомагає моделі розпізнавати обʼєкти не залежно від умов освітлення\n",
    "    A.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2, p=0.5),\n",
    "    # моделі в PyTorch очікують вхідні дані у вигляді тензорів\n",
    "    ToTensorV2(p=1.0),\n",
    "], bbox_params=A.BboxParams(format='albumentations', label_fields=['labels']))\n",
    "\n",
    "dataset = FruitDataset(data_dir='/Users/matvejzasadko/Downloads/All/Study/NNetworks/Lb1/archive/train_zip/train', transforms=transform, image_size=(256, 256))\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "for images, targets in dataloader:\n",
    "    print(images[0].shape, targets[0]['boxes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b45a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.ops import roi_pool\n",
    "\n",
    "class RCNN(nn.Module):\n",
    "    def __init__(self, num_classes, num_rois=9):\n",
    "        super(RCNN, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = models.alexnet(pretrained=True).features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        \n",
    "        self.bbox_head = nn.Linear(4096, num_rois * 4)\n",
    "        \n",
    "        self.class_head = nn.Linear(4096, num_rois * num_classes)\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_rois = num_rois\n",
    "\n",
    "    def forward(self, x, rois):\n",
    "        features = self.feature_extractor(x)\n",
    "        \n",
    "        pooled_features = roi_pool(features, rois, output_size=(6, 6))\n",
    "        \n",
    "        x = self.avgpool(pooled_features)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        bbox_coords = self.bbox_head(x)\n",
    "        bbox_coords = bbox_coords.view(-1, self.num_rois, 4)\n",
    "\n",
    "        class_scores = self.class_head(x)\n",
    "        class_scores = class_scores.view(-1, self.num_rois, self.num_classes)\n",
    "        \n",
    "        return bbox_coords, class_scores\n",
    "\n",
    "num_classes = 4 \n",
    "num_rois = 9\n",
    "model = RCNN(num_classes=num_classes, num_rois=num_rois)\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 512, 512) \n",
    "dummy_rois = torch.tensor([[0, 50, 50, 400, 400]], dtype=torch.float)\n",
    "\n",
    "bbox_coords, class_scores = model(dummy_input, dummy_rois)\n",
    "\n",
    "print(\"Bounding Box Coordinates:\", bbox_coords)\n",
    "print(\"Class Scores:\", class_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8421cb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], BBox Loss: 0.1433, Class Loss: 1.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], BBox Loss: 0.1349, Class Loss: 1.0681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], BBox Loss: 0.1256, Class Loss: 1.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], BBox Loss: 0.1058, Class Loss: 0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], BBox Loss: 0.0822, Class Loss: 0.9086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], BBox Loss: 0.0660, Class Loss: 0.8236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], BBox Loss: 0.0543, Class Loss: 0.7487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], BBox Loss: 0.0518, Class Loss: 0.7004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], BBox Loss: 0.0524, Class Loss: 0.6731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], BBox Loss: 0.0519, Class Loss: 0.6589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], BBox Loss: 0.0512, Class Loss: 0.6541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], BBox Loss: 0.0512, Class Loss: 0.6498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], BBox Loss: 0.0517, Class Loss: 0.6468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], BBox Loss: 0.0520, Class Loss: 0.6452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], BBox Loss: 0.0516, Class Loss: 0.6443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], BBox Loss: 0.0513, Class Loss: 0.6434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], BBox Loss: 0.0518, Class Loss: 0.6437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], BBox Loss: 0.0512, Class Loss: 0.6434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], BBox Loss: 0.0522, Class Loss: 0.6439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], BBox Loss: 0.0511, Class Loss: 0.6411\n",
      "Тренування завершено.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "num_epochs = 20\n",
    "learning_rate = 0.00001\n",
    "\n",
    "num_classes = 3 \n",
    "num_rois = 9\n",
    "model = RCNN(num_classes=num_classes, num_rois=num_rois)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "bbox_loss_fn = nn.MSELoss() \n",
    "class_loss_fn = nn.CrossEntropyLoss() \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_bbox_loss = 0.0\n",
    "    total_class_loss = 0.0\n",
    "    \n",
    "    for images, targets in dataloader: \n",
    "        images = torch.stack(images).to(device)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        rois = []\n",
    "        for idx in range(len(images)):\n",
    "            roi = torch.tensor([[idx, 50, 50, 400, 400],\n",
    "                                [idx, 100, 100, 300, 300]], dtype=torch.float, device=device)\n",
    "            rois.append(roi)\n",
    "        \n",
    "        rois = torch.cat(rois, dim=0) \n",
    "        \n",
    "        bbox_preds, class_preds = model(images, rois)\n",
    "        \n",
    "        batch_bbox_loss = 0.0\n",
    "        batch_class_loss = 0.0\n",
    "\n",
    "        for i, target in enumerate(targets):\n",
    "            num_boxes = target['boxes'].shape[0]\n",
    "            if num_boxes > num_rois:\n",
    "                bboxes = target['boxes'][:num_rois]\n",
    "                labels = target['labels'][:num_rois]\n",
    "            else:\n",
    "                padding_boxes = torch.zeros((num_rois - num_boxes, 4), device=device)\n",
    "                padding_labels = torch.zeros(num_rois - num_boxes, dtype=torch.long, device=device)\n",
    "                bboxes = torch.cat([target['boxes'], padding_boxes], dim=0)\n",
    "                labels = torch.cat([target['labels'], padding_labels], dim=0)\n",
    "                \n",
    "            batch_bbox_loss += bbox_loss_fn(bbox_preds[i], bboxes)\n",
    "            batch_class_loss += class_loss_fn(class_preds[i], labels)\n",
    "        \n",
    "        batch_bbox_loss /= len(targets)\n",
    "        batch_class_loss /= len(targets)\n",
    "\n",
    "        loss = batch_bbox_loss + batch_class_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_bbox_loss += batch_bbox_loss.item()\n",
    "        total_class_loss += batch_class_loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], BBox Loss: {total_bbox_loss/len(dataloader):.4f}, Class Loss: {total_class_loss/len(dataloader):.4f}\")\n",
    "\n",
    "print(\"Тренування завершено.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "123d8c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестова BBox Loss: 0.0498\n",
      "Точність класифікації: 85.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_dataset = FruitDataset(data_dir='/Users/matvejzasadko/Downloads/All/Study/NNetworks/Lb1/archive/test_zip/test', \n",
    "                            transforms=transform, \n",
    "                            image_size=(256, 256))\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "def evaluate_model(model, test_loader, device, num_rois=9):\n",
    "    model.eval()  \n",
    "    total_bbox_loss = 0.0\n",
    "    all_true_labels = []\n",
    "    all_pred_labels = []\n",
    "\n",
    "    bbox_loss_fn = nn.MSELoss() \n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for images, targets in test_loader:\n",
    "            images = torch.stack(images).to(device)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            rois = []\n",
    "            for idx in range(len(images)):\n",
    "                roi = torch.tensor([[idx, 50, 50, 400, 400],\n",
    "                                    [idx, 100, 100, 300, 300]], dtype=torch.float, device=device)\n",
    "                rois.append(roi)\n",
    "            \n",
    "            rois = torch.cat(rois, dim=0)  \n",
    "\n",
    "            bbox_preds, class_preds = model(images, rois)\n",
    "\n",
    "            batch_bbox_loss = 0.0\n",
    "\n",
    "            for i, target in enumerate(targets):\n",
    "                num_boxes = target['boxes'].shape[0]\n",
    "                if num_boxes > num_rois:\n",
    "                    bboxes = target['boxes'][:num_rois]\n",
    "                    labels = target['labels'][:num_rois]\n",
    "                else:\n",
    "                    padding_boxes = torch.zeros((num_rois - num_boxes, 4), device=device)\n",
    "                    padding_labels = torch.zeros(num_rois - num_boxes, dtype=torch.long, device=device)\n",
    "                    bboxes = torch.cat([target['boxes'], padding_boxes], dim=0)\n",
    "                    labels = torch.cat([target['labels'], padding_labels], dim=0)\n",
    "\n",
    "                batch_bbox_loss += bbox_loss_fn(bbox_preds[i], bboxes).item()\n",
    "\n",
    "                _, predicted_classes = torch.max(class_preds[i], 1)\n",
    "                all_true_labels.extend(labels.cpu().numpy())\n",
    "                all_pred_labels.extend(predicted_classes.cpu().numpy())\n",
    "\n",
    "            total_bbox_loss += batch_bbox_loss / len(targets)\n",
    "\n",
    "    avg_bbox_loss = total_bbox_loss / len(test_loader)\n",
    "\n",
    "    class_accuracy = accuracy_score(all_true_labels, all_pred_labels)\n",
    "\n",
    "    print(f\"Тестова BBox Loss: {avg_bbox_loss:.4f}\")\n",
    "    print(f\"Точність класифікації: {class_accuracy * 100:.2f}%\")\n",
    "\n",
    "evaluate_model(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca521611",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCNN_Tune(nn.Module):\n",
    "    def __init__(self, num_classes, num_rois=9, fc_hidden_size=1024, dropout_rate=0.3, kernel_size=5, pretrained=True):\n",
    "        super(RCNN_Tune, self).__init__()\n",
    "\n",
    "        self.feature_extractor = models.alexnet(pretrained=pretrained).features\n",
    "        self._update_kernel_size(kernel_size)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 6 * 6, fc_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(fc_hidden_size, fc_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate)\n",
    "        )\n",
    "\n",
    "        self.bbox_head = nn.Linear(fc_hidden_size, num_rois * 4)\n",
    "        self.class_head = nn.Linear(fc_hidden_size, num_rois * num_classes)\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_rois = num_rois\n",
    "\n",
    "    def _update_kernel_size(self, kernel_size):\n",
    "        \n",
    "        for layer in self.feature_extractor:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                layer.kernel_size = (kernel_size, kernel_size)\n",
    "                layer.padding = (kernel_size // 2, kernel_size // 2)  \n",
    "        \n",
    "    def forward(self, x, rois):\n",
    "        features = self.feature_extractor(x)\n",
    "        \n",
    "        pooled_features = roi_pool(features, rois, output_size=(6, 6))\n",
    "        \n",
    "        x = self.avgpool(pooled_features)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        bbox_coords = self.bbox_head(x)\n",
    "        bbox_coords = bbox_coords.view(-1, self.num_rois, 4)\n",
    "\n",
    "        class_scores = self.class_head(x)\n",
    "        class_scores = class_scores.view(-1, self.num_rois, self.num_classes)\n",
    "        \n",
    "        return bbox_coords, class_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "206324c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchRCNNEstimator(BaseEstimator):\n",
    "    def __init__(self, num_classes=4, num_rois=9, fc_hidden_size=4096, dropout_rate=0.5, kernel_size=3, learning_rate=0.001, num_epochs=5, pretrained=True):\n",
    "        self.num_classes = num_classes\n",
    "        self.num_rois = num_rois\n",
    "        self.fc_hidden_size = fc_hidden_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.kernel_size = kernel_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.pretrained = pretrained\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        model = RCNN_Tune(num_classes=self.num_classes, num_rois=self.num_rois, \n",
    "                     fc_hidden_size=self.fc_hidden_size, dropout_rate=self.dropout_rate, \n",
    "                     kernel_size=self.kernel_size, pretrained=self.pretrained)\n",
    "        model.to(self.device)\n",
    "        return model\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model.train()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        bbox_loss_fn = nn.MSELoss()\n",
    "        class_loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            total_bbox_loss = 0.0\n",
    "            total_class_loss = 0.0\n",
    "            \n",
    "            for images, targets in dataloader:\n",
    "                images = torch.stack(images).to(self.device)\n",
    "                targets = [{k: v.to(self.device) for k, v in t.items()} for t in targets]\n",
    "                \n",
    "                rois = torch.cat([torch.tensor([[idx, 50, 50, 400, 400], [idx, 100, 100, 300, 300]], dtype=torch.float, device=self.device) for idx in range(len(images))], dim=0)\n",
    "                bbox_preds, class_preds = self.model(images, rois)\n",
    "                \n",
    "                batch_bbox_loss = 0.0\n",
    "                batch_class_loss = 0.0\n",
    "                \n",
    "                for i, target in enumerate(targets):\n",
    "                    num_boxes = target['boxes'].shape[0]\n",
    "                    if num_boxes > self.model.num_rois:\n",
    "                        bboxes = target['boxes'][:self.model.num_rois]\n",
    "                        labels = target['labels'][:self.model.num_rois]\n",
    "                    else:\n",
    "                        padding_boxes = torch.zeros((self.model.num_rois - num_boxes, 4), device=self.device)\n",
    "                        padding_labels = torch.zeros(self.model.num_rois - num_boxes, dtype=torch.long, device=self.device)\n",
    "                        bboxes = torch.cat([target['boxes'], padding_boxes], dim=0)\n",
    "                        labels = torch.cat([target['labels'], padding_labels], dim=0)\n",
    "                    \n",
    "                    batch_bbox_loss += bbox_loss_fn(bbox_preds[i], bboxes)\n",
    "                    batch_class_loss += class_loss_fn(class_preds[i], labels)\n",
    "                \n",
    "                batch_bbox_loss /= len(targets)\n",
    "                batch_class_loss /= len(targets)\n",
    "                \n",
    "                loss = batch_bbox_loss + batch_class_loss\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_bbox_loss += batch_bbox_loss.item()\n",
    "                total_class_loss += batch_class_loss.item()\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def score(self, X, y):\n",
    "        self.model.eval()\n",
    "        total_correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, targets in dataloader:\n",
    "                images = torch.stack(images).to(self.device)\n",
    "                targets = [{k: v.to(self.device) for k, v in t.items()} for t in targets]\n",
    "                \n",
    "                rois = torch.cat([torch.tensor([[idx, 50, 50, 400, 400], [idx, 100, 100, 300, 300]], dtype=torch.float, device=self.device) for idx in range(len(images))], dim=0)\n",
    "                _, class_preds = self.model(images, rois)\n",
    "                \n",
    "                for i, target in enumerate(targets):\n",
    "                    labels = target['labels'].to(self.device)\n",
    "                    num_labels = min(len(labels), class_preds[i].shape[0])\n",
    "                    pred_labels = class_preds[i][:num_labels].argmax(dim=1)\n",
    "                    total_correct += (pred_labels == labels[:num_labels]).sum().item()\n",
    "                    total += num_labels\n",
    "        return total_correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efa89add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестуємо: fc_hidden_size=2048, dropout_rate=0.4, kernel_size=5, learning_rate=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matvejzasadko/.pyenv/versions/3.8.13/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/matvejzasadko/.pyenv/versions/3.8.13/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1957\n",
      "\n",
      "Тестуємо: fc_hidden_size=2048, dropout_rate=0.4, kernel_size=8, learning_rate=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1957\n",
      "\n",
      "Тестуємо: fc_hidden_size=2048, dropout_rate=0.5, kernel_size=5, learning_rate=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1957\n",
      "\n",
      "Тестуємо: fc_hidden_size=2048, dropout_rate=0.5, kernel_size=8, learning_rate=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1957\n",
      "\n",
      "Тестуємо: fc_hidden_size=4096, dropout_rate=0.4, kernel_size=5, learning_rate=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1957\n",
      "\n",
      "Тестуємо: fc_hidden_size=4096, dropout_rate=0.4, kernel_size=8, learning_rate=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1957\n",
      "\n",
      "Тестуємо: fc_hidden_size=4096, dropout_rate=0.5, kernel_size=5, learning_rate=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1957\n",
      "\n",
      "Тестуємо: fc_hidden_size=4096, dropout_rate=0.5, kernel_size=8, learning_rate=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1957\n",
      "\n",
      "Найкращі параметри: {'fc_hidden_size': 2048, 'dropout_rate': 0.4, 'kernel_size': 5, 'learning_rate': 0.0001}\n",
      "Найкращий результат: 0.1956989247311828\n",
      "\n",
      "Важливість гіперпараметрів:\n",
      "fc_hidden_size: 0.0000\n",
      "dropout_rate: 0.0000\n",
      "kernel_size: 0.0000\n",
      "learning_rate: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "param_grid = {\n",
    "    'fc_hidden_size': [2048, 4096],\n",
    "    'dropout_rate': [0.4, 0.5],\n",
    "    'kernel_size': [5, 8],\n",
    "    'learning_rate': [0.0001]\n",
    "}\n",
    "\n",
    "best_params = None\n",
    "best_score = 0\n",
    "results = []  \n",
    "\n",
    "all_combinations = list(itertools.product(\n",
    "    param_grid['fc_hidden_size'],\n",
    "    param_grid['dropout_rate'],\n",
    "    param_grid['kernel_size'],\n",
    "    param_grid['learning_rate']\n",
    "))\n",
    "\n",
    "for fc_hidden_size, dropout_rate, kernel_size, learning_rate in all_combinations:\n",
    "    print(f\"Тестуємо: fc_hidden_size={fc_hidden_size}, dropout_rate={dropout_rate}, kernel_size={kernel_size}, learning_rate={learning_rate}\")\n",
    "    \n",
    "    estimator = PyTorchRCNNEstimator(\n",
    "        num_classes=4,\n",
    "        num_rois=9,\n",
    "        fc_hidden_size=fc_hidden_size,\n",
    "        dropout_rate=dropout_rate,\n",
    "        kernel_size=kernel_size,\n",
    "        learning_rate=learning_rate,\n",
    "        num_epochs=5\n",
    "    )\n",
    "    \n",
    "    estimator.fit(None, None) \n",
    "    \n",
    "    score = estimator.score(None, None)\n",
    "    \n",
    "    results.append({\n",
    "        'fc_hidden_size': fc_hidden_size,\n",
    "        'dropout_rate': dropout_rate,\n",
    "        'kernel_size': kernel_size,\n",
    "        'learning_rate': learning_rate,\n",
    "        'accuracy': score\n",
    "    })\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = {\n",
    "            'fc_hidden_size': fc_hidden_size,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'kernel_size': kernel_size,\n",
    "            'learning_rate': learning_rate\n",
    "        }\n",
    "    print(f\"Score: {score:.4f}\\n\")\n",
    "\n",
    "print(\"Найкращі параметри:\", best_params)\n",
    "print(\"Найкращий результат:\", best_score)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "X = df[['fc_hidden_size', 'dropout_rate', 'kernel_size', 'learning_rate']]\n",
    "y = df['accuracy']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_scaled, y)\n",
    "\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "print(\"\\nВажливість гіперпараметрів:\")\n",
    "for name, importance in zip(X.columns, feature_importances):\n",
    "    print(f\"{name}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ddd0e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matvejzasadko/.pyenv/versions/3.8.13/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/matvejzasadko/.pyenv/versions/3.8.13/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], BBox Loss: 0.0766, Class Loss: 1.0930\n",
      "Найкращі ваги збережені на епосі 1 з BBox Loss: 0.0766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15], BBox Loss: 0.0762, Class Loss: 1.0838\n",
      "Найкращі ваги збережені на епосі 2 з BBox Loss: 0.0762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15], BBox Loss: 0.0736, Class Loss: 1.0733\n",
      "Найкращі ваги збережені на епосі 3 з BBox Loss: 0.0736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15], BBox Loss: 0.0712, Class Loss: 1.0603\n",
      "Найкращі ваги збережені на епосі 4 з BBox Loss: 0.0712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/15], BBox Loss: 0.0684, Class Loss: 1.0438\n",
      "Найкращі ваги збережені на епосі 5 з BBox Loss: 0.0684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/15], BBox Loss: 0.0658, Class Loss: 1.0222\n",
      "Найкращі ваги збережені на епосі 6 з BBox Loss: 0.0658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/15], BBox Loss: 0.0643, Class Loss: 0.9953\n",
      "Найкращі ваги збережені на епосі 7 з BBox Loss: 0.0643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/15], BBox Loss: 0.0577, Class Loss: 0.9609\n",
      "Найкращі ваги збережені на епосі 8 з BBox Loss: 0.0577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/15], BBox Loss: 0.0538, Class Loss: 0.9189\n",
      "Найкращі ваги збережені на епосі 9 з BBox Loss: 0.0538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15], BBox Loss: 0.0491, Class Loss: 0.8698\n",
      "Найкращі ваги збережені на епосі 10 з BBox Loss: 0.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/15], BBox Loss: 0.0435, Class Loss: 0.8134\n",
      "Найкращі ваги збережені на епосі 11 з BBox Loss: 0.0435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/15], BBox Loss: 0.0396, Class Loss: 0.7546\n",
      "Найкращі ваги збережені на епосі 12 з BBox Loss: 0.0396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/15], BBox Loss: 0.0354, Class Loss: 0.6941\n",
      "Найкращі ваги збережені на епосі 13 з BBox Loss: 0.0354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/15], BBox Loss: 0.0334, Class Loss: 0.6345\n",
      "Найкращі ваги збережені на епосі 14 з BBox Loss: 0.0334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], BBox Loss: 0.0313, Class Loss: 0.5814\n",
      "Найкращі ваги збережені на епосі 15 з BBox Loss: 0.0313\n",
      "Завантажено найкращі ваги в model_param.\n",
      "Тренування завершено.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "num_epochs = 15\n",
    "learning_rate = 0.00001\n",
    "\n",
    "num_classes = 3 \n",
    "num_rois = 9\n",
    "model_param = RCNN_Tune(num_classes=num_classes, num_rois=num_rois)\n",
    "optimizer = optim.Adam(model_param.parameters(), lr=learning_rate)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_param.to(device)\n",
    "\n",
    "bbox_loss_fn = nn.MSELoss() \n",
    "class_loss_fn = nn.CrossEntropyLoss() \n",
    "\n",
    "bbox_loss_history = []\n",
    "class_loss_history = []\n",
    "\n",
    "best_bbox_loss = float('inf')\n",
    "best_model_state = None  \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_param.train()\n",
    "    total_bbox_loss = 0.0\n",
    "    total_class_loss = 0.0\n",
    "    \n",
    "    for images, targets in dataloader: \n",
    "        images = torch.stack(images).to(device)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        rois = []\n",
    "        for idx in range(len(images)):\n",
    "            roi = torch.tensor([[idx, 50, 50, 400, 400],\n",
    "                                [idx, 100, 100, 300, 300]], dtype=torch.float, device=device)\n",
    "            rois.append(roi)\n",
    "        \n",
    "        rois = torch.cat(rois, dim=0) \n",
    "        \n",
    "        bbox_preds, class_preds = model_param(images, rois)\n",
    "        \n",
    "        batch_bbox_loss = 0.0\n",
    "        batch_class_loss = 0.0\n",
    "\n",
    "        for i, target in enumerate(targets):\n",
    "            num_boxes = target['boxes'].shape[0]\n",
    "            if num_boxes > num_rois:\n",
    "                bboxes = target['boxes'][:num_rois]\n",
    "                labels = target['labels'][:num_rois]\n",
    "            else:\n",
    "                padding_boxes = torch.zeros((num_rois - num_boxes, 4), device=device)\n",
    "                padding_labels = torch.zeros(num_rois - num_boxes, dtype=torch.long, device=device)\n",
    "                bboxes = torch.cat([target['boxes'], padding_boxes], dim=0)\n",
    "                labels = torch.cat([target['labels'], padding_labels], dim=0)\n",
    "                \n",
    "            batch_bbox_loss += bbox_loss_fn(bbox_preds[i], bboxes)\n",
    "            batch_class_loss += class_loss_fn(class_preds[i], labels)\n",
    "        \n",
    "        batch_bbox_loss /= len(targets)\n",
    "        batch_class_loss /= len(targets)\n",
    "\n",
    "        loss = batch_bbox_loss + batch_class_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_bbox_loss += batch_bbox_loss.item()\n",
    "        total_class_loss += batch_class_loss.item()\n",
    "    \n",
    "    avg_bbox_loss = total_bbox_loss / len(dataloader)\n",
    "    avg_class_loss = total_class_loss / len(dataloader)\n",
    "    bbox_loss_history.append(avg_bbox_loss)\n",
    "    class_loss_history.append(avg_class_loss)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], BBox Loss: {avg_bbox_loss:.4f}, Class Loss: {avg_class_loss:.4f}\")\n",
    "    \n",
    "    if avg_bbox_loss < best_bbox_loss:\n",
    "        best_bbox_loss = avg_bbox_loss\n",
    "        best_model_state = model_param.state_dict() \n",
    "        print(f\"Найкращі ваги збережені на епосі {epoch+1} з BBox Loss: {avg_bbox_loss:.4f}\")\n",
    "\n",
    "if best_model_state is not None:\n",
    "    model_param.load_state_dict(best_model_state)\n",
    "    print(\"Завантажено найкращі ваги в model_param.\")\n",
    "\n",
    "print(\"Тренування завершено.\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), bbox_loss_history, label='BBox Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('BBox Loss')\n",
    "plt.title('Зміна BBox Loss по епохах')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6694652d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестова BBox Loss: 0.0274\n",
      "Точність класифікації: 85.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_dataset = FruitDataset(data_dir='/Users/matvejzasadko/Downloads/All/Study/NNetworks/Lb1/archive/test_zip/test', \n",
    "                            transforms=transform, \n",
    "                            image_size=(256, 256))\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "def evaluate_model(model, test_loader, device, num_rois=9):\n",
    "    model.eval()  \n",
    "    total_bbox_loss = 0.0\n",
    "    all_true_labels = []\n",
    "    all_pred_labels = []\n",
    "\n",
    "    bbox_loss_fn = nn.MSELoss() \n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for images, targets in test_loader:\n",
    "            images = torch.stack(images).to(device)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            rois = []\n",
    "            for idx in range(len(images)):\n",
    "                roi = torch.tensor([[idx, 50, 50, 400, 400],\n",
    "                                    [idx, 100, 100, 300, 300]], dtype=torch.float, device=device)\n",
    "                rois.append(roi)\n",
    "            \n",
    "            rois = torch.cat(rois, dim=0)  \n",
    "\n",
    "            bbox_preds, class_preds = model(images, rois)\n",
    "\n",
    "            batch_bbox_loss = 0.0\n",
    "\n",
    "            for i, target in enumerate(targets):\n",
    "                num_boxes = target['boxes'].shape[0]\n",
    "                if num_boxes > num_rois:\n",
    "                    bboxes = target['boxes'][:num_rois]\n",
    "                    labels = target['labels'][:num_rois]\n",
    "                else:\n",
    "                    padding_boxes = torch.zeros((num_rois - num_boxes, 4), device=device)\n",
    "                    padding_labels = torch.zeros(num_rois - num_boxes, dtype=torch.long, device=device)\n",
    "                    bboxes = torch.cat([target['boxes'], padding_boxes], dim=0)\n",
    "                    labels = torch.cat([target['labels'], padding_labels], dim=0)\n",
    "\n",
    "                batch_bbox_loss += bbox_loss_fn(bbox_preds[i], bboxes).item()\n",
    "\n",
    "                _, predicted_classes = torch.max(class_preds[i], 1)\n",
    "                all_true_labels.extend(labels.cpu().numpy())\n",
    "                all_pred_labels.extend(predicted_classes.cpu().numpy())\n",
    "\n",
    "            total_bbox_loss += batch_bbox_loss / len(targets)\n",
    "\n",
    "    avg_bbox_loss = total_bbox_loss / len(test_loader)\n",
    "\n",
    "    class_accuracy2 = accuracy_score(all_true_labels, all_pred_labels)\n",
    "\n",
    "    print(f\"Тестова BBox Loss: {avg_bbox_loss:.4f}\")\n",
    "    print(f\"Точність класифікації: {class_accuracy2 * 100:.2f}%\")\n",
    "\n",
    "evaluate_model(model_param, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879e529d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7568f007",
   "metadata": {},
   "source": [
    "Epoch [7/10], BBox Loss: 0.0307, Class Loss: 0.4847 'fc_hidden_size': 2048, Epoch [9/10], BBox Loss: 0.0301, Class Loss: 0.4827 'dropout_rate': 0.4 Epoch [7/10], BBox Loss: 0.0299, Class Loss: 0.4830 'kernel_size': 5\n",
    "\n",
    "Впорядковані за значимістю гіперпараметри - це 'kernel_size' 'dropout_rate' 'fc_hidden_size'\n",
    "Найкращі параметри: {'fc_hidden_size': 2048, 'dropout_rate': 0.4, 'kernel_size': 5, 'learning_rate': 0.0001}\n",
    "    \n",
    "Але найкращий сет параметрів це базовий на тестових даних модель показала \n",
    "Тестова BBox Loss: 0.0297\n",
    "Точність класифікації: 82.22%\n",
    "    \n",
    "А з параметрами: Тестова BBox Loss: 0.2716\n",
    "                 Точність класифікації: 3.89%!!!!!!!!!!!! --Broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d0de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac64a64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87596932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d207db45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
